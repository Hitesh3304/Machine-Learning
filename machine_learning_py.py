# -*- coding: utf-8 -*-
"""machine-Learning.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mu_HxeiNZe9gznEY6MlrSC3BnHjUF_Nb
"""

import pandas as pd

df =pd.read_csv('vgsales.csv')
df.shape

df.describe()

### Decision tree  and Accuracy

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

music_data = pd.read_csv('music.csv')
X = music_data.drop(columns=['genre'])
y = music_data['genre']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

model = DecisionTreeClassifier()
model.fit(X_train,y_train)
predictions = model.predict(X_test)

score = accuracy_score(y_test, predictions)
score

## persisting Models

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree

music_data = pd.read_csv('music.csv')
X = music_data.drop(columns=['genre'])
y = music_data['genre']




model = DecisionTreeClassifier()
model.fit(X,y)

tree.export_graphviz(model, out_file='music-recommender.dot',
                     feature_names=['age', 'gender'],
                     class_names=sorted(y.unique()),
                     label='all',
                     rounded=True,
                     filled=True)

import numpy as np
a= np.array([1,2,3])
a

b= np.array([[1,2,3],[4,5,6]])
b

b.shape

b.dtype

a.itemsize

f = np.random.rand(4,2)*100
f

import numpy

x = numpy.random.uniform(0.0, 5.0, 20)  #it wil generate 20 numbers between 0 and 5

print(x)

import matplotlib.pyplot as plt

plt.hist(x)

import pandas as pd
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt

# Training data
X = [[1], [2], [3], [4], [5]]
y = [30000, 35000, 40000, 45000, 50000]

# Train model
model = LinearRegression()
model.fit(X, y)

# Predict
prediction = model.predict([[6]])
print("Predicted salary for 6 years experience:", prediction[0])

# Visualize
plt.scatter(X, y, color='blue')
plt.plot(X, model.predict(X), color='red')
plt.xlabel("Years of Experience")
plt.ylabel("Salary")
plt.title("Linear Regression Example")
plt.show()

import pandas
from sklearn import linear_model

df = pandas.read_csv("Book1.csv")

X = df[['Weight', 'Volume']]
y = df['CO2']

regr = linear_model.LinearRegression()
regr.fit(X, y)

#predict the CO2 emission of a car where the weight is 2300kg, and the volume is 1300cm3:
predictedCO2 = regr.predict([[2300, 1300]])

print(predictedCO2)

import pandas as pd
import matplotlib.pyplot as plt

df =pd.read_csv('Book1.csv')
df

plt.figure(figsize=(14,5))
x= df['Car']
y=df['Volume']

plt.bar(x,y)
plt.xlabel('Car')
plt.ylabel('Volume')
plt.show()

df

from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt

reg = LinearRegression()
reg.fit(df[['Weight']],df['CO2']) #fit is used to train the data

plt.scatter(df['Weight'], df['CO2'], color='blue')

# Plot the regression line
plt.plot(df['Weight'], reg.predict(df[['Weight']]), color='red')

plt.xlabel('Weight')
plt.ylabel('CO2 Emissions')
plt.title('Linear Regression: Weight vs CO2')
plt.grid(True)
plt.show()

print("Intercept:", reg.intercept_)
print("Slope:", reg.coef_[0])
predicted = reg.predict([[2300]])  # Predict CO2 for car with weight 2300
print("Predicted CO2 for 2300 kg car:", predicted[0])

from sklearn.linear_model import LinearRegression

X = [[1], [2], [3]]
y = [3, 5, 7]

reg = LinearRegression()
reg.fit(X, y)

print("Intercept:", reg.intercept_)
print("Slope (Coefficient):", reg.coef_[0])

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

X = [[2], [3], [5], [7], [9]]

y = [50, 60, 80, 90, 95]

reg = LinearRegression()
reg.fit(X, y)

predict = reg.predict([[4]])
print("predict: ",predict)
print("intercept:" , reg.intercept_)
print("slope:" , reg.coef_[0])

plt.scatter(X, y, color='blue')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
import numpy as np

X = [[2], [3], [5], [7], [9]]
y = [50, 60, 80, 90, 95]

reg = LinearRegression()
reg.fit(X, y)

predict = reg.predict([[4]])
print("Prediction for 4 hours:", predict[0])
print("Intercept:", reg.intercept_)
print("Slope:", reg.coef_[0])

# Plotting points
plt.scatter(X, y, color='blue')

# Plotting regression line
X_range = np.linspace(min(x[0] for x in X), max(x[0] for x in X), 100).reshape(-1, 1)
y_range = reg.predict(X_range)
plt.plot(X_range, y_range, color='red')

plt.xlabel('Hours Studied')
plt.ylabel('Exam Score')
plt.title('Linear Regression Fit')
plt.show()

import numpy as np
import matplotlib.pyplot as plt

X= np.random.uniform(5,25,8)

plt.hist(X,20)
plt.show()

import matplotlib.pyplot as plt
import numpy
from sklearn import metrics

actual = numpy.random.binomial(1,.9,size = 1000)
predicted = numpy.random.binomial(1,.9,size = 1000)

confusion_matrix = metrics.confusion_matrix(actual, predicted)

Accuracy = metrics.accuracy_score(actual, predicted)
Precision = metrics.precision_score(actual, predicted)
Recall = metrics.recall_score(actual, predicted)
F1_Score = metrics.f1_score(actual, predicted)

print("Confusion Matrix:")
print(confusion_matrix)
print("Accuracy:", Accuracy)
print("Precision:", Precision)
print("Recall:", Recall)
print("F1 Score:", F1_Score)

#precision = metrics.percision_score(actual,predicted)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])

cm_display.plot()
plt.show()

import numpy as np
import matplotlib.pyplot as plt

x = [99,86,87,88,111,86,103,87,94,78,77,85,86]

mean = np.mean(x)
median = np.median(x)
std = np.std(x)

print("Mean: ", mean)
print("Median: ", median)
print("Standard Deviation: ", std)

Percentile=np.percentile(x,75)
print(Percentile)

data = np.random.uniform(0,100,10)

  print(data)

  plt.boxplot(data)
  plt.show()

  plt.hist(data)
  plt.show()

nrml = np.random.normal(0,100,10)

print(nrml)

plt.hist(nrml)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
x= np.random.uniform(0,100,10)
y= np.random.uniform(0,100,10)

plt.scatter(x,y)
plt.show()

from sklearn.linear_model import LinearRegression
import numpy as np
import matplotlib.pyplot as plt

x= np.random.uniform(0,100,10)
y= np.random.uniform(0,100,10)

x=x.reshape(-1,1)
y=y.reshape(-1,1)

reg = LinearRegression()
reg.fit(x,y)

predict= reg.predict([[50]])
print(predict)
plt.scatter(x,y)
plt.plot(x,reg.predict(x),color='red')
plt.show()

#Handling missing values
from sklearn.impute import SimpleImputer
import numpy as np

data = [[1, 2], [np.nan, 3], [7, 6]]

imputer = SimpleImputer(strategy='mean')
imputed_data = imputer.fit_transform(data)

print(imputed_data)

import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('music.csv')
df

df = pd.read_csv('music.csv')

# Mapping dictionary (keys as strings)
d = {'HipHop': 1, 'Classical': 2, 'Jazz': 3, 'Rock': 4}

# Map genre column to numeric codes
df['genre'] = df['genre'].map(d)

print(df)

import pandas as pd
from sklearn.tree import DecisionTreeClassifier, plot_tree
import matplotlib.pyplot as plt

# Load data
df = pd.read_csv('music.csv')

# Map genres to numbers
d = {'HipHop': 1, 'Classical': 2, 'Jazz': 3, 'Rock': 4, 'Dance': 5, 'Acoustic': 6}
df['genre'] = df['genre'].map(d)

# Define feature columns
features = ['age', 'gender']

# Extract features and target
X = df[features]
y = df['genre']

# Train decision tree classifier
dtree = DecisionTreeClassifier()
dtree.fit(X, y)

# Plot decision tree
plt.figure(figsize=(12, 6))
plot_tree(dtree, feature_names=features, class_names=[str(k) for k in d.keys()], filled=True)
plt.show()

#Lineaer regression

import pandas as pd
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt

# Training data
X = [[1], [2], [3], [4], [5]]
y = [30000, 35000, 40000, 45000, 50000]

# Train model
model = LinearRegression()
model.fit(X, y)  # X is the independent variable and y is the dependent variable
#fit

# Predict
prediction = model.predict([[6]])
print("Predicted salary for 6 years experience:", prediction[0])

# Visualize
plt.scatter(X, y, color='blue')
plt.plot(X, model.predict(X), color='red')
plt.xlabel("Years of Experience")
plt.ylabel("Salary")
plt.title("Linear Regression Example")
plt.show()

import pandas as pd
from io import StringIO

data = """
customer_id,age,income,spending_score,education_level,employment_status,credit_score,num_purchases,avg_purchase_amount,time_since_last_purchase,loyalty_years,satisfaction_rating,gender,location_type,preferred_category,seasonal_buyer,risk_category,churn_probability
1,23,35000,78,Bachelor,Employed,720,45,89.50,15,2.5,4.2,Female,Urban,Electronics,Yes,Low,0.15
2,45,67000,65,Master,Employed,680,32,156.75,8,5.2,3.8,Male,Suburban,Clothing,No,Medium,0.25
3,34,52000,82,Bachelor,Employed,750,67,124.30,3,4.1,4.5,Female,Urban,Home,Yes,Low,0.12
4,56,89000,45,PhD,Employed,690,28,210.80,22,7.8,3.2,Male,Rural,Books,No,Medium,0.35
5,29,41000,91,High School,Employed,710,78,67.90,5,3.2,4.7,Female,Urban,Fashion,Yes,Low,0.08
6,38,58000,72,Bachelor,Self-employed,665,41,178.25,12,6.1,4.0,Male,Suburban,Sports,No,Medium,0.22
7,62,95000,38,Master,Retired,640,19,287.60,45,12.3,2.8,Female,Rural,Health,No,High,0.55
8,27,33000,85,Bachelor,Unemployed,580,52,95.40,18,1.8,3.9,Male,Urban,Gaming,Yes,High,0.45
9,41,71000,59,Master,Employed,725,35,198.70,7,8.4,3.5,Female,Suburban,Beauty,No,Low,0.18
10,33,46000,88,Bachelor,Employed,695,61,112.80,4,4.7,4.6,Male,Urban,Electronics,Yes,Low,0.10
11,52,82000,42,PhD,Employed,715,25,245.30,28,9.2,3.1,Female,Suburban,Books,No,Medium,0.38
12,25,38000,79,High School,Employed,650,48,78.20,11,2.1,4.3,Male,Urban,Fashion,Yes,Medium,0.28
13,47,63000,67,Master,Employed,705,38,167.90,14,6.8,3.7,Female,Rural,Home,No,Low,0.20
14,31,49000,84,Bachelor,Self-employed,675,55,103.60,6,3.8,4.4,Male,Urban,Sports,Yes,Medium,0.16
15,59,87000,41,Master,Employed,660,22,276.40,31,11.5,2.9,Female,Suburban,Health,No,High,0.48
16,26,36000,86,Bachelor,Employed,690,58,88.70,9,2.3,4.5,Male,Urban,Gaming,Yes,Low,0.14
17,43,69000,61,Master,Employed,720,33,189.50,16,7.1,3.6,Female,Suburban,Beauty,No,Medium,0.24
18,35,54000,80,Bachelor,Employed,740,49,139.20,7,5.4,4.1,Male,Urban,Electronics,Yes,Low,0.13
19,48,74000,55,PhD,Employed,685,29,223.80,25,8.9,3.3,Female,Rural,Books,No,Medium,0.32
20,30,44000,89,High School,Employed,665,64,91.30,2,3.5,4.8,Male,Urban,Fashion,Yes,Low,0.09
21,54,85000,46,Master,Self-employed,650,26,258.70,38,10.7,3.0,Female,Suburban,Health,No,High,0.52
22,28,40000,83,Bachelor,Employed,705,51,105.80,13,2.9,4.2,Male,Urban,Sports,Yes,Medium,0.19
23,44,66000,63,Master,Employed,680,36,172.40,19,6.5,3.8,Female,Rural,Home,No,Medium,0.27
24,32,47000,87,Bachelor,Employed,715,56,96.90,8,4.2,4.4,Male,Urban,Gaming,Yes,Low,0.11
25,57,91000,39,PhD,Retired,625,18,294.50,42,13.1,2.7,Female,Rural,Books,No,High,0.58
"""

df = pd.read_csv(StringIO(data))
df.to_csv("customer_data.csv", index=False)
print("File saved as 'customer_data.csv'")

import pandas as pd
import matplotlib.pyplot as plt
import sklearn as sk
from sklearn.linear_model import LinearRegression

df = pd.read_csv('customer_data.csv')

df

from sklearn.linear_model import LinearRegression

# Independent variables (features)
X = df[['age', 'credit_score', 'num_purchases']]

# Dependent variable (target)
y = df['income']

# Train model
model = LinearRegression()
model.fit(X, y)

# Example: predict income for a new customer
# age=30, credit_score=700, num_purchases=15
new_data = [[30, 700, 15]]
prediction = model.predict(new_data)

print(f"Predicted income: {prediction[0]}")

mean_age = df['age'].mean()
print(f"Mean age: {mean_age}")

"""Decision Tree Regression"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor, plot_tree
import numpy as np

df = pd.read_csv('Data.csv')
X = df[['Average_Pulse']]
y = df['Calorie_Burnage']

# Fit Decision Tree Regressor
model = DecisionTreeRegressor(random_state=0)
model.fit(X, y)

# Plot the decision tree
plt.figure(figsize=(12, 6))
plot_tree(model, feature_names=['Average_Pulse'], filled=True)
plt.title("Decision Tree Regressor for Average Pulse vs Calorie Burnage")
plt.show()

print(df)

"""Linear regression

"""

from sklearn.linear_model import LinearRegression

X = df[['Average_Pulse']]
y = df['Calorie_Burnage']

model = LinearRegression()
model.fit(X,y)

prediction = model.predict([[126]])
print(prediction)
plt.scatter(X,y,color ='blue', label ='Data Points')
plt.plot(X,model.predict(X),color='red',label = 'Linear Regression')
plt.scatter(126,prediction,color = 'green',label ='predicted')
plt.xlabel('Average_Pulse')
plt.ylabel('Calorie_Burnage')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

df = pd.read_csv('Book1.csv')

df

x = df['Volume']
y = df['CO2']

model = LinearRegression()
model.fit(x.values.reshape(-1,1),y)

prediction = model.predict([[2300]])
print(prediction)

plt.scatter(x,y)
plt.scatter(2300,prediction,color='green')
plt.plot(x,model.predict(x.values.reshape(-1,1)),color='red')
plt.show()
'''
x = df['Volume']
y = df['CO2']

model = LinearRegression()
model.fit(x.values.reshape(-1,1),y)

prediction = model.predict([[2300]])
print(prediction)

plt.scatter(x,y)
plt.scatter(2300,prediction,color='green')
plt.plot(x,model.predict(x.values.reshape(-1,1)),color='red')
plt.show()
explain
'''

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

df = pd.read_csv('tested.csv')
df.head()

# Features and target
x = df[['Pclass']]           # 2D array for features
y = df['Survived']        # 1D array for target

# Train model
model = LinearRegression()
model.fit(x, y)

# Predict survival probability for a 30-year-old
prediction = model.predict([[30]])
print("Predicted survival (as probability):", prediction[0])

df['Age'].isnull().sum()

df['Age'][df['Age'].isnull()]